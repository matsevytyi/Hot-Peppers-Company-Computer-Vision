{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Shared Evaluation (Base + LoRA)\n",
        "\n",
        "Evaluates base checkpoint and all LoRA adapters from one shared config.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    for candidate in (start, *start.parents):\n",
        "        if (candidate / '.git').exists():\n",
        "            return candidate\n",
        "    return start\n",
        "\n",
        "\n",
        "REPO_ROOT = find_repo_root(Path.cwd().resolve())\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "EVAL_CONFIG_PATH = REPO_ROOT / 'configs/eval/shared_eval.yaml'\n",
        "EVAL_MODE = 'quick'  # quick | full\n",
        "EVAL_CONFIG_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.dependencies import check_packages, assert_required_packages\n",
        "\n",
        "status = check_packages(['torch', 'torchvision', 'yaml', 'safetensors', 'einops', 'tqdm', 'pandas'])\n",
        "status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_required_packages(['torch', 'torchvision', 'yaml', 'safetensors', 'einops'])\n",
        "print('Core dependencies look good')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.contracts import EvalConfig\n",
        "\n",
        "cfg = EvalConfig.from_yaml(EVAL_CONFIG_PATH).eval\n",
        "cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for dataset_cfg in cfg['datasets']:\n",
        "    manifest_path = REPO_ROOT / dataset_cfg['manifest']\n",
        "    if not manifest_path.exists():\n",
        "        raise FileNotFoundError(f'Missing manifest: {manifest_path}')\n",
        "print('All manifests found')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cmd = [\n",
        "    sys.executable,\n",
        "    str(REPO_ROOT / 'scripts/pipelines/eval_from_config.py'),\n",
        "    '--config',\n",
        "    str(EVAL_CONFIG_PATH),\n",
        "    '--mode',\n",
        "    EVAL_MODE,\n",
        "]\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "metrics_dir = REPO_ROOT / cfg.get('output_dir', 'results/shared_eval')\n",
        "metrics_csv = metrics_dir / 'metrics.csv'\n",
        "metrics_json = metrics_dir / 'metrics.json'\n",
        "\n",
        "print('Metrics CSV :', metrics_csv)\n",
        "print('Metrics JSON:', metrics_json)\n",
        "\n",
        "if metrics_csv.exists():\n",
        "    df = pd.read_csv(metrics_csv)\n",
        "    display(df)\n",
        "else:\n",
        "    print('metrics.csv not found')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done checklist\n",
        "\n",
        "- [ ] All dataset manifests exist\n",
        "- [ ] Quick eval completed without exception\n",
        "- [ ] metrics.json and metrics.csv were generated\n",
        "- [ ] Full eval run completed after all training jobs\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
