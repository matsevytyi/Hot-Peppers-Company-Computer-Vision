{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train LoRA ACDC Adverse (Mamba-Vision)\n",
        "\n",
        "Notebook-first pipeline with safety gates:\n",
        "\n",
        "- dependency checks\n",
        "- optional FiftyOne export + manifest generation\n",
        "- one-batch shape/loss sanity\n",
        "- mandatory pilot before full run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import random\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    for candidate in (start, *start.parents):\n",
        "        if (candidate / '.git').exists():\n",
        "            return candidate\n",
        "    return start\n",
        "\n",
        "\n",
        "REPO_ROOT = find_repo_root(Path.cwd().resolve())\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "RUN_MODE = 'pilot'  # pilot | full\n",
        "PREPARE_DATA = False\n",
        "AUTO_CONFIRM_FULL = False\n",
        "\n",
        "print('Repo root:', REPO_ROOT)\n",
        "print('Run mode:', RUN_MODE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG_PATH = REPO_ROOT / 'configs/training/lora_acdc.yaml'\n",
        "CONFIG_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.dependencies import check_packages, assert_required_packages\n",
        "\n",
        "required = ['torch', 'torchvision', 'yaml', 'safetensors', 'tqdm', 'einops']\n",
        "optional = ['fiftyone', 'mambavision', 'wandb']\n",
        "status = check_packages(required + optional)\n",
        "status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_required_packages(['torch', 'torchvision', 'yaml', 'safetensors', 'einops'])\n",
        "print('Core dependencies look good')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.contracts import TrainConfig\n",
        "\n",
        "cfg = TrainConfig.from_yaml(CONFIG_PATH)\n",
        "cfg.model.model_file = str((REPO_ROOT / cfg.model.model_file).resolve())\n",
        "cfg.ckpt.output_path = str((REPO_ROOT / cfg.ckpt.output_path).resolve())\n",
        "if cfg.model.base_checkpoint:\n",
        "    cfg.model.base_checkpoint = str((REPO_ROOT / cfg.model.base_checkpoint).resolve())\n",
        "if cfg.data.get('lora_output_path'):\n",
        "    cfg.data['lora_output_path'] = str((REPO_ROOT / cfg.data['lora_output_path']).resolve())\n",
        "cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.fiftyone_data import prepare_zoo_split_export\n",
        "\n",
        "if PREPARE_DATA:\n",
        "    print('Preparing train split export...')\n",
        "    prepare_zoo_split_export(\n",
        "        zoo_name=cfg.data['zoo_name'],\n",
        "        split=cfg.data['split_train'],\n",
        "        dataset_name=f\"{cfg.run_name}_{cfg.data['split_train']}\",\n",
        "        export_dir=str(REPO_ROOT / cfg.data['export_train_dir']),\n",
        "        manifest_path=str(REPO_ROOT / cfg.data['manifest_train']),\n",
        "        source=cfg.data.get('source', 'fiftyone_zoo'),\n",
        "        max_samples=cfg.data.get('max_samples_train'),\n",
        "        time_of_day=cfg.data.get('time_of_day'),\n",
        "        local_dataset_dir=cfg.data.get('local_dataset_dir'),\n",
        "        local_dataset_type=cfg.data.get('local_dataset_type', 'COCODetectionDataset'),\n",
        "    )\n",
        "\n",
        "    print('Preparing val split export...')\n",
        "    prepare_zoo_split_export(\n",
        "        zoo_name=cfg.data['zoo_name'],\n",
        "        split=cfg.data['split_val'],\n",
        "        dataset_name=f\"{cfg.run_name}_{cfg.data['split_val']}\",\n",
        "        export_dir=str(REPO_ROOT / cfg.data['export_val_dir']),\n",
        "        manifest_path=str(REPO_ROOT / cfg.data['manifest_val']),\n",
        "        source=cfg.data.get('source', 'fiftyone_zoo'),\n",
        "        max_samples=cfg.data.get('max_samples_val'),\n",
        "        time_of_day=cfg.data.get('time_of_day'),\n",
        "        local_dataset_dir=cfg.data.get('local_dataset_dir'),\n",
        "        local_dataset_type=cfg.data.get('local_dataset_type', 'COCODetectionDataset'),\n",
        "    )\n",
        "else:\n",
        "    print('PREPARE_DATA=False -> expecting existing manifests')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.coco_dataset import build_dataloader\n",
        "from pipelines.contracts import DatasetManifest\n",
        "\n",
        "train_manifest = DatasetManifest.from_json(REPO_ROOT / cfg.data['manifest_train'])\n",
        "val_manifest = DatasetManifest.from_json(REPO_ROOT / cfg.data['manifest_val'])\n",
        "\n",
        "train_loader = build_dataloader(\n",
        "    train_manifest,\n",
        "    image_size=cfg.train.image_size,\n",
        "    batch_size=cfg.train.batch_size,\n",
        "    num_workers=cfg.train.num_workers,\n",
        "    shuffle=True,\n",
        "    max_samples=cfg.data.get('max_samples_train'),\n",
        ")\n",
        "val_loader = build_dataloader(\n",
        "    val_manifest,\n",
        "    image_size=cfg.train.image_size,\n",
        "    batch_size=cfg.train.batch_size,\n",
        "    num_workers=cfg.train.num_workers,\n",
        "    shuffle=False,\n",
        "    max_samples=cfg.data.get('max_samples_val'),\n",
        ")\n",
        "\n",
        "print('Train images:', train_manifest.num_images, 'instances:', train_manifest.num_instances)\n",
        "print('Val images:', val_manifest.num_images, 'instances:', val_manifest.num_instances)\n",
        "print('Train batches:', len(train_loader), 'Val batches:', len(val_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.lora import (\n",
        "    collect_trainable_parameter_summary,\n",
        "    configure_lora_training,\n",
        "    inject_lora_modules,\n",
        ")\n",
        "from pipelines.model_loader import create_model_from_config\n",
        "from pipelines.training import load_checkpoint, resolve_device\n",
        "\n",
        "\n",
        "device = resolve_device(cfg.train.device)\n",
        "model = create_model_from_config(cfg.model, device=str(device))\n",
        "\n",
        "if cfg.model.base_checkpoint:\n",
        "    load_checkpoint(REPO_ROOT / cfg.model.base_checkpoint, model)\n",
        "    print('Loaded base checkpoint:', REPO_ROOT / cfg.model.base_checkpoint)\n",
        "\n",
        "if cfg.lora is not None:\n",
        "    replaced_layers = inject_lora_modules(\n",
        "        model.backbone,\n",
        "        rank=cfg.lora.rank,\n",
        "        alpha=cfg.lora.alpha,\n",
        "        dropout=cfg.lora.dropout,\n",
        "        target_rule=cfg.lora.target_rule,\n",
        "    )\n",
        "    configure_lora_training(model, freeze_neck=cfg.freeze.neck, freeze_head=cfg.freeze.head)\n",
        "    print('LoRA layers injected:', len(replaced_layers))\n",
        "\n",
        "summary = collect_trainable_parameter_summary(model)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.yolo_ops import MultiScaleYoloLoss\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = MultiScaleYoloLoss(num_classes=cfg.model.num_classes).to(device)\n",
        "\n",
        "images, targets = next(iter(train_loader))\n",
        "images = images.to(device)\n",
        "targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "\n",
        "losses = criterion(outputs, targets)\n",
        "print('Scale outputs:', [tuple(o.shape) for o in outputs])\n",
        "print('Sanity loss:', {k: float(v.detach().cpu()) for k, v in losses.items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if device.type == 'cuda':\n",
        "    allocated = torch.cuda.memory_allocated(device) / (1024 ** 3)\n",
        "    reserved = torch.cuda.memory_reserved(device) / (1024 ** 3)\n",
        "    print(f'GPU memory allocated: {allocated:.2f} GB')\n",
        "    print(f'GPU memory reserved : {reserved:.2f} GB')\n",
        "else:\n",
        "    print('Non-CUDA device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.training import fit_model\n",
        "\n",
        "pilot_history = fit_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    train_cfg=cfg.train,\n",
        "    ckpt_cfg=cfg.ckpt,\n",
        "    num_classes=cfg.model.num_classes,\n",
        "    run_mode='pilot',\n",
        ")\n",
        "\n",
        "print('Pilot train loss:', pilot_history['train'][-1].loss)\n",
        "print('Pilot val loss  :', pilot_history['val'][-1].loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_MODE == 'full':\n",
        "    if AUTO_CONFIRM_FULL:\n",
        "        confirm = 'yes'\n",
        "    else:\n",
        "        confirm = input('Pilot complete. Start FULL training? (yes/no): ').strip().lower()\n",
        "    if confirm != 'yes':\n",
        "        raise RuntimeError('Cancelled by user before full training')\n",
        "else:\n",
        "    print('RUN_MODE is pilot -> full run step is skipped')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_history = None\n",
        "if RUN_MODE == 'full':\n",
        "    full_history = fit_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        train_cfg=cfg.train,\n",
        "        ckpt_cfg=cfg.ckpt,\n",
        "        num_classes=cfg.model.num_classes,\n",
        "        run_mode='full',\n",
        "    )\n",
        "    print('Full train loss:', full_history['train'][-1].loss)\n",
        "    print('Full val loss  :', full_history['val'][-1].loss)\n",
        "else:\n",
        "    print('Pilot-only run completed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pipelines.lora import save_lora_adapters\n",
        "\n",
        "if cfg.lora is not None:\n",
        "    lora_path = REPO_ROOT / cfg.data['lora_output_path']\n",
        "    lora_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    save_lora_adapters(\n",
        "        model,\n",
        "        output_path=str(lora_path),\n",
        "        metadata={\n",
        "            'run_name': cfg.run_name,\n",
        "            'base_checkpoint': cfg.model.base_checkpoint,\n",
        "        },\n",
        "    )\n",
        "    print('Saved LoRA adapters:', lora_path)\n",
        "\n",
        "print('Train checkpoint path:', REPO_ROOT / cfg.ckpt.output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done checklist\n",
        "\n",
        "- [ ] Dependencies verified\n",
        "- [ ] Manifests found and non-empty\n",
        "- [ ] Shape/loss sanity passed\n",
        "- [ ] Pilot run completed\n",
        "- [ ] Full run confirmed (if needed)\n",
        "- [ ] Checkpoint/adapter saved\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
