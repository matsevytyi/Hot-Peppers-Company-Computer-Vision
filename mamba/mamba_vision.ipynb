{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mamba UAV Detector - Incremental Training Notebook\n",
                "\n",
                "This notebook implements an **incremental training pipeline** for the Mamba-based UAV detector.\n",
                "\n",
                "## Storage-Aware Workflow\n",
                "Due to storage constraints (~10GB available), we train one UAV type at a time:\n",
                "```\n",
                "Download UAV-A ‚Üí Train ‚Üí Save checkpoint ‚Üí Delete UAV-A\n",
                "Download UAV-B ‚Üí Load checkpoint ‚Üí Continue training ‚Üí Delete UAV-B\n",
                "... repeat for all 12 UAV types ...\n",
                "```\n",
                "\n",
                "## Table of Contents\n",
                "1. [Setup & Imports](#1-setup)\n",
                "2. [Download Utilities](#2-download)\n",
                "3. [Configuration](#3-config)\n",
                "4. [Model Setup](#4-model)\n",
                "5. [Training Loop (per UAV part)](#5-training)\n",
                "6. [Cleanup](#6-cleanup)\n",
                "7. [Evaluation](#7-evaluation)\n",
                "8. [Export Model](#8-export)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='1-setup'></a>\n",
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1\n",
                        "2\n"
                    ]
                },
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'xmltodict'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MambaDetectorModule\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     download_uav_part,\n\u001b[1;32m     26\u001b[0m     cleanup_uav_part,\n\u001b[1;32m     27\u001b[0m     get_available_uav_types,\n\u001b[1;32m     28\u001b[0m     create_dataloaders,\n\u001b[1;32m     29\u001b[0m     DATASET_URLS,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Device detection\u001b[39;00m\n",
                        "File \u001b[0;32m~/Downloads/Hot-Peppers-Company-Computer-Vision/mamba/dataset.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshared\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_bboxes, parse_voc_xml\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Dataset Download URLs\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     30\u001b[0m DATASET_URLS: Dict[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.scidb.cn/download?fileId=9282ae0baf2816c72bfff8164d735c83&path=/V4/Fixed-wing-UAV-A.zip&fileName=Fixed-wing-UAV-A.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     ],\n\u001b[1;32m     58\u001b[0m }\n",
                        "File \u001b[0;32m~/Downloads/Hot-Peppers-Company-Computer-Vision/shared/parser.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxmltodict\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_voc_xml\u001b[39m(xml_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a VOC XML file and return the annotation dict.\"\"\"\u001b[39;00m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xmltodict'"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import warnings\n",
                "from pathlib import Path\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"1\") # do not remove prints (–∫–æ—Å—Ç–∏–ª—å)\n",
                "# Add project root to path\n",
                "PROJECT_ROOT = Path(os.getcwd()).parent\n",
                "if str(PROJECT_ROOT) not in sys.path:\n",
                "    sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "# Core imports\n",
                "import torch\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "print(\"2\")\n",
                "\n",
                "# Local imports\n",
                "from mamba.config import Config\n",
                "from mamba.trainer import MambaDetectorModule\n",
                "from mamba.dataset import (\n",
                "    download_uav_part,\n",
                "    cleanup_uav_part,\n",
                "    get_available_uav_types,\n",
                "    create_dataloaders,\n",
                "    DATASET_URLS,\n",
                ")\n",
                "\n",
                "print(\"3\")\n",
                "\n",
                "# Device detection\n",
                "if torch.cuda.is_available():\n",
                "    DEVICE = 'cuda'\n",
                "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
                "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "elif torch.backends.mps.is_available():\n",
                "    DEVICE = 'mps'\n",
                "    print(\"üçé Using Apple MPS (with LSTM fallback for Mamba)\")\n",
                "else:\n",
                "    DEVICE = 'cpu'\n",
                "    print(\"üíª Using CPU\")\n",
                "\n",
                "print(f\"\\nüì¶ Available UAV types for download: {list(DATASET_URLS.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='2-download'></a>\n",
                "## 2. Download Utilities\n",
                "\n",
                "Functions to download, extract, and cleanup UAV parts one at a time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìÅ Currently downloaded UAV types: ['A']\n",
                        "\n",
                        "üíæ Estimated storage per UAV type:\n",
                        "   - UAV-A to UAV-F: ~10GB each\n",
                        "   - Total dataset: ~100GB\n",
                        "   - With incremental training, you only need ~10GB at a time\n"
                    ]
                }
            ],
            "source": [
                "# Check what's currently downloaded\n",
                "DATA_ROOT = PROJECT_ROOT / \"data\" / \"MMFW-UAV\" / \"raw\"\n",
                "available = get_available_uav_types(str(DATA_ROOT))\n",
                "print(f\"üìÅ Currently downloaded UAV types: {available if available else 'None'}\")\n",
                "\n",
                "# Estimate storage per UAV type (~1-2GB each)\n",
                "print(\"\\nüíæ Estimated storage per UAV type:\")\n",
                "print(\"   - UAV-A to UAV-F: ~10GB each\")\n",
                "print(\"   - Total dataset: ~100GB\")\n",
                "print(\"   - With incremental training, you only need ~10GB at a time\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='3-config'></a>\n",
                "## 3. Configuration\n",
                "\n",
                "Training hyperparameters. Adjust based on your hardware."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Configuration loaded\n",
                        "   Checkpoint dir: /teamspace/studios/this_studio/Hot-Peppers-Company-Computer-Vision/outputs/checkpoints\n"
                    ]
                }
            ],
            "source": [
                "# Training configuration\n",
                "config = Config()\n",
                "\n",
                "# Data settings\n",
                "config.data.data_root = str(DATA_ROOT)\n",
                "config.data.batch_size = 2  # Reduce if OOM\n",
                "config.data.num_workers = 2  # 0 for debugging\n",
                "config.data.sequence_length = 8\n",
                "config.data.stride = 5\n",
                "config.data.img_size = 640\n",
                "config.data.sensor_type = \"Zoom\"  # Zoom, Wide, or Infrared\n",
                "config.data.view = \"Top_Down\"  # Top_Down, Horizontal, or Bottom_Up\n",
                "\n",
                "# Model settings\n",
                "config.model.mamba_type = \"vision\"\n",
                "config.model.backbone = \"mobilevit_s\"\n",
                "config.model.d_model = 256\n",
                "config.model.d_state = 16\n",
                "config.model.mamba_layers = 4\n",
                "\n",
                "# Training settings\n",
                "config.training.max_epochs = 10  # Epochs per UAV part\n",
                "config.training.lr = 1e-3\n",
                "config.training.weight_decay = 1e-4\n",
                "\n",
                "# Checkpoint path\n",
                "CHECKPOINT_DIR = PROJECT_ROOT / \"outputs\" / \"checkpoints\"\n",
                "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "MOD_ARCH = \"vis_mamba_simple_head\"\n",
                "LATEST_CHECKPOINT = CHECKPOINT_DIR / f\"{MOD_ARCH}_latest.ckpt\"\n",
                "\n",
                "print(f\"‚úÖ Configuration loaded\")\n",
                "print(f\"   Checkpoint dir: {CHECKPOINT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='4-model'></a>\n",
                "## 4. Model Setup\n",
                "\n",
                "Initialize model, optionally loading from checkpoint for continued training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üÜï Creating new model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ New model created\n",
                        "\n",
                        "üìä Model stats:\n",
                        "   Total parameters: 6,894,245\n",
                        "   Trainable parameters: 6,894,245\n"
                    ]
                }
            ],
            "source": [
                "# Initialize or load model\n",
                "if LATEST_CHECKPOINT.exists():\n",
                "    print(f\"üìÇ Loading checkpoint: {LATEST_CHECKPOINT}\")\n",
                "    model = MambaDetectorModule.load_from_checkpoint(\n",
                "        str(LATEST_CHECKPOINT),\n",
                "        config=config,\n",
                "    )\n",
                "    print(\"‚úÖ Model loaded from checkpoint\")\n",
                "else:\n",
                "    print(\"üÜï Creating new model\")\n",
                "    model = MambaDetectorModule(config)\n",
                "    print(\"‚úÖ New model created\")\n",
                "\n",
                "# Print model summary\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"\\nüìä Model stats:\")\n",
                "print(f\"   Total parameters: {total_params:,}\")\n",
                "print(f\"   Trainable parameters: {trainable_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='5-training'></a>\n",
                "## 5. Training Loop (per UAV part)\n",
                "\n",
                "**‚ö†Ô∏è Run this cell for each UAV part you want to train on:**\n",
                "1. Change `CURRENT_UAV` to the UAV type you want to download and train\n",
                "2. Run the cell - it will download, train, and save checkpoint\n",
                "3. Optionally run the cleanup cell to delete downloaded data\n",
                "4. Repeat with the next UAV type"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "üéØ TRAINING ON UAV-A\n",
                        "============================================================\n",
                        "\n",
                        "üì• Step 1: Downloading data...\n",
                        "‚úÖ UAV-A already exists at: /teamspace/studios/this_studio/Hot-Peppers-Company-Computer-Vision/data/MMFW-UAV/raw/Fixed-wing-UAV-A\n",
                        "   Skipping download. Delete folder to re-download.\n"
                    ]
                }
            ],
            "source": [
                "# ===== CHANGE THIS FOR EACH PART =====\n",
                "CURRENT_UAV = \"A\"  # Options: \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n",
                "# =====================================\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"üéØ TRAINING ON UAV-{CURRENT_UAV}\")\n",
                "print(f\"{'='*60}\\n\")\n",
                "\n",
                "# Step 1: Download this UAV part\n",
                "print(\"üì• Step 1: Downloading data...\")\n",
                "try:\n",
                "    uav_path = download_uav_part(CURRENT_UAV, output_dir=str(DATA_ROOT))\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Download failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "old GPU memory allocated: 21.95 GB\n",
                        "old GPU memory reserved: 22.02 GB\n",
                        "new GPU memory allocated: 0.00 GB\n",
                        "new GPU memory reserved: 22.02 GB\n",
                        "new GPU memory stats: |===========================================================================|\n",
                        "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\n",
                        "|===========================================================================|\n",
                        "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Allocated memory      |      0 B   |  22511 MiB |  68792 MiB |  68792 MiB |\n",
                        "|       from large pool |      0 B   |  22458 MiB |  68641 MiB |  68641 MiB |\n",
                        "|       from small pool |      0 B   |     53 MiB |    150 MiB |    150 MiB |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Active memory         |      0 B   |  22511 MiB |  68792 MiB |  68792 MiB |\n",
                        "|       from large pool |      0 B   |  22458 MiB |  68641 MiB |  68641 MiB |\n",
                        "|       from small pool |      0 B   |     53 MiB |    150 MiB |    150 MiB |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Requested memory      |      0 B   |  22511 MiB |  68792 MiB |  68792 MiB |\n",
                        "|       from large pool |      0 B   |  22458 MiB |  68641 MiB |  68641 MiB |\n",
                        "|       from small pool |      0 B   |     53 MiB |    150 MiB |    150 MiB |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| GPU reserved memory   |  22544 MiB |  22554 MiB |  22564 MiB |  20480 KiB |\n",
                        "|       from large pool |  22500 MiB |  22500 MiB |  22500 MiB |      0 KiB |\n",
                        "|       from small pool |     44 MiB |     54 MiB |     64 MiB |  20480 KiB |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
                        "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
                        "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Allocations           |       0    |     807    |    2440    |    2440    |\n",
                        "|       from large pool |       0    |     188    |     776    |     776    |\n",
                        "|       from small pool |       0    |     620    |    1664    |    1664    |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Active allocs         |       0    |     807    |    2440    |    2440    |\n",
                        "|       from large pool |       0    |     188    |     776    |     776    |\n",
                        "|       from small pool |       0    |     620    |    1664    |    1664    |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
                        "|       from large pool |       0    |       0    |       0    |       0    |\n",
                        "|       from small pool |       0    |       0    |       0    |       0    |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
                        "|       from large pool |       0    |       0    |       0    |       0    |\n",
                        "|       from small pool |       0    |       0    |       0    |       0    |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
                        "|---------------------------------------------------------------------------|\n",
                        "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
                        "|===========================================================================|\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "import gc\n",
                "\n",
                "print(f\"old GPU memory allocated: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB\")\n",
                "print(f\"old GPU memory reserved: {torch.cuda.memory_reserved(0)/1024**3:.2f} GB\")\n",
                "\n",
                "# Add before trainer.fit()\n",
                "torch.cuda.empty_cache()\n",
                "gc.collect()\n",
                "\n",
                "# Also check what's using memory\n",
                "print(f\"new GPU memory allocated: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB\")\n",
                "print(f\"new GPU memory reserved: {torch.cuda.memory_reserved(0)/1024**3:.2f} GB\")\n",
                "print(f\"new GPU memory stats: {torch.cuda.memory_summary(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using 16bit Automatic Mixed Precision (AMP)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "üéØ TRAINING ON UAV-A\n",
                        "============================================================\n",
                        "\n",
                        "\n",
                        "üìÅ Step 2: Creating dataloaders for UAV-A...\n",
                        "grabbed frames,  1451 0_1_000001.jpg\n",
                        "grabbed frames,  1451 0_1_000001.jpg\n",
                        "grabbed frames,  1451 0_1_000001.jpg\n",
                        "   Train batches: 101\n",
                        "   Val batches: 22\n",
                        "\n",
                        "üèãÔ∏è Step 3: Setting up trainer...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üöÄ Step 4: Training for 31 epochs...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "  | Name      | Type             | Params | Mode | FLOPs\n",
                        "--------------------------------------------------------------\n",
                        "0 | model     | MambaUAVDetector | 6.9 M  | eval | 0    \n",
                        "1 | criterion | DetectionLoss    | 0      | eval | 0    \n",
                        "--------------------------------------------------------------\n",
                        "6.9 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "6.9 M     Total params\n",
                        "27.577    Total estimated model params size (MB)\n",
                        "0         Modules in train mode\n",
                        "470       Modules in eval mode\n",
                        "0         Total Flops\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "14d21b9e20d44910a469705a87d957a2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b9bd908b46184a6c862fb9d089a71416",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1c3e1c363c864caab1799fc7efffcf50",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`weights_only` was not set, defaulting to `False`.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üíæ Step 5: Saving checkpoint...\n",
                        "‚úÖ Saved to: /teamspace/studios/this_studio/Hot-Peppers-Company-Computer-Vision/outputs/checkpoints/van_mamba_simple_head_latest.ckpt\n",
                        "\n",
                        "============================================================\n",
                        "‚úÖ FINISHED TRAINING ON UAV-A\n",
                        "   Best val_loss: inf\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "# ===== CHANGE THIS FOR EACH PART =====\n",
                "EPOCHS_THIS_PART = 31  # Epochs to train on this part\n",
                "# =====================================\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"üéØ TRAINING ON UAV-{CURRENT_UAV}\")\n",
                "print(f\"{'='*60}\\n\")\n",
                "\n",
                "from mamba.dataset import create_dataloaders\n",
                "\n",
                "# Step 2: Create dataloaders for this UAV part\n",
                "print(f\"\\nüìÅ Step 2: Creating dataloaders for UAV-{CURRENT_UAV}...\")\n",
                "train_loader, val_loader, test_loader = create_dataloaders(\n",
                "    data_root=str(DATA_ROOT),\n",
                "    batch_size=config.data.batch_size,\n",
                "    num_workers=config.data.num_workers,\n",
                "    sequence_length=config.data.sequence_length,\n",
                "    stride=config.data.stride,\n",
                "    img_size=config.data.img_size,\n",
                "    sensor_type=config.data.sensor_type,\n",
                "    view=config.data.view,\n",
                "    uav_types=[CURRENT_UAV],  # Only train on this UAV part!\n",
                ")\n",
                "print(f\"   Train batches: {len(train_loader)}\")\n",
                "print(f\"   Val batches: {len(val_loader)}\")\n",
                "\n",
                "# Step 3: Setup trainer\n",
                "print(f\"\\nüèãÔ∏è Step 3: Setting up trainer...\")\n",
                "checkpoint_callback = ModelCheckpoint(\n",
                "    dirpath=str(CHECKPOINT_DIR),\n",
                "    filename=f\"uav-{CURRENT_UAV}-\" + \"{epoch:02d}-{val_loss:.4f}\",\n",
                "    save_top_k=1,\n",
                "    monitor=\"val_loss\",\n",
                "    mode=\"min\",\n",
                "    save_last=True,\n",
                ")\n",
                "\n",
                "early_stopping = EarlyStopping(\n",
                "    monitor=\"val_loss\",\n",
                "    patience=5,\n",
                "    mode=\"min\",\n",
                ")\n",
                "\n",
                "trainer = pl.Trainer(\n",
                "    max_epochs=EPOCHS_THIS_PART,\n",
                "    accelerator=\"auto\",\n",
                "    devices=1,\n",
                "    precision=\"16-mixed\" if DEVICE == \"cuda\" else 32, # 16-mixed does not support sigmoid, switched to logits\n",
                "    callbacks=[checkpoint_callback, early_stopping],\n",
                "    enable_progress_bar=True,\n",
                "    gradient_clip_val=1.0,\n",
                "    log_every_n_steps=10,\n",
                ")\n",
                "\n",
                "# Step 4: Train!\n",
                "print(f\"\\nüöÄ Step 4: Training for {EPOCHS_THIS_PART} epochs...\")\n",
                "trainer.fit(model, train_loader, val_loader)\n",
                "\n",
                "# Step 5: Save checkpoint for next part\n",
                "print(f\"\\nüíæ Step 5: Saving checkpoint...\")\n",
                "trainer.save_checkpoint(str(LATEST_CHECKPOINT))\n",
                "print(f\"‚úÖ Saved to: {LATEST_CHECKPOINT}\")\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"‚úÖ FINISHED TRAINING ON UAV-{CURRENT_UAV}\")\n",
                "print(f\"   Best val_loss: {checkpoint_callback.best_model_score:.4f}\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='6-cleanup'></a>\n",
                "## 6. Cleanup (Optional)\n",
                "\n",
                "Delete downloaded data to free up storage before downloading the next UAV part."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Delete the UAV part we just trained on to free space\n",
                "cleanup_uav_part(CURRENT_UAV, data_dir=str(DATA_ROOT))\n",
                "\n",
                "# Verify deletion\n",
                "available = get_available_uav_types(str(DATA_ROOT))\n",
                "print(f\"\\nüìÅ Currently downloaded UAV types: {available if available else 'None'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìã Training Progress Tracker\n",
                "\n",
                "Keep track of which UAV parts you've trained on:\n",
                "\n",
                "| UAV | Status | Epochs | Notes |\n",
                "|-----|--------|--------|-------|\n",
                "| A   | ‚¨ú Not started |  |  |\n",
                "| B   | ‚¨ú Not started |  |  |\n",
                "| C   | ‚¨ú Not started |  |  |\n",
                "| D   | ‚¨ú Not started |  |  |\n",
                "| E   | ‚¨ú Not started |  |  |\n",
                "| F   | ‚¨ú Not started |  |  |\n",
                "\n",
                "After each training run, update the status to ‚úÖ Completed."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='7-evaluation'></a>\n",
                "## 7. Evaluation\n",
                "\n",
                "Evaluate the final model after training on all UAV parts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "if LATEST_CHECKPOINT.exists():\n",
                "    print(f\"üìÇ Loading final model from: {LATEST_CHECKPOINT}\")\n",
                "    model = MambaDetectorModule.load_from_checkpoint(\n",
                "        str(LATEST_CHECKPOINT),\n",
                "        config=config,\n",
                "    )\n",
                "    model.eval()\n",
                "    print(\"‚úÖ Model loaded for evaluation\")\n",
                "else:\n",
                "    print(\"‚ùå No checkpoint found. Train the model first.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize predictions on a sample\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as patches\n",
                "import numpy as np\n",
                "\n",
                "# Make sure a UAV part is downloaded for testing\n",
                "available = get_available_uav_types(str(DATA_ROOT))\n",
                "if not available:\n",
                "    print(\"‚ö†Ô∏è No UAV data available. Download a part first.\")\n",
                "else:\n",
                "    # Create test loader with available data\n",
                "    _, _, test_loader = create_dataloaders(\n",
                "        data_root=str(DATA_ROOT),\n",
                "        batch_size=1,\n",
                "        num_workers=0,\n",
                "        sequence_length=config.data.sequence_length,\n",
                "        stride=config.data.stride,\n",
                "        img_size=config.data.img_size,\n",
                "        sensor_type=config.data.sensor_type,\n",
                "        view=config.data.view,\n",
                "        uav_types=available,\n",
                "    )\n",
                "    \n",
                "    # Get a sample batch\n",
                "    images, targets = next(iter(test_loader))\n",
                "    \n",
                "    # Run inference\n",
                "    with torch.no_grad():\n",
                "        predictions = model(images.to(DEVICE))\n",
                "    \n",
                "    # Visualize first frame of sequence\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "    \n",
                "    # Denormalize for visualization\n",
                "    mean = np.array([0.485, 0.456, 0.406])\n",
                "    std = np.array([0.229, 0.224, 0.225])\n",
                "    \n",
                "    for i, ax in enumerate(axes[:min(3, images.shape[1])]):\n",
                "        img = images[0, i].cpu().numpy().transpose(1, 2, 0)\n",
                "        img = (img * std + mean).clip(0, 1)\n",
                "        \n",
                "        ax.imshow(img)\n",
                "        ax.set_title(f\"Frame {i+1}\")\n",
                "        \n",
                "        # Draw predicted bbox\n",
                "        pred = predictions[0, i].cpu().numpy()\n",
                "        if pred[4] > 0.5:  # confidence threshold\n",
                "            x_center, y_center, w, h = pred[:4]\n",
                "            x_center *= config.data.img_size\n",
                "            y_center *= config.data.img_size\n",
                "            w *= config.data.img_size\n",
                "            h *= config.data.img_size\n",
                "            \n",
                "            rect = patches.Rectangle(\n",
                "                (x_center - w/2, y_center - h/2), w, h,\n",
                "                linewidth=2, edgecolor='r', facecolor='none'\n",
                "            )\n",
                "            ax.add_patch(rect)\n",
                "        \n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(str(PROJECT_ROOT / 'outputs' / 'sample_prediction.png'), dpi=150)\n",
                "    plt.show()\n",
                "    print(f\"\\nüì∏ Saved visualization to: outputs/sample_prediction.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='8-export'></a>\n",
                "## 8. Export Model\n",
                "\n",
                "Export the trained model for deployment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to TorchScript\n",
                "EXPORT_DIR = PROJECT_ROOT / \"outputs\" / \"exported\"\n",
                "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "if LATEST_CHECKPOINT.exists():\n",
                "    model = MambaDetectorModule.load_from_checkpoint(\n",
                "        str(LATEST_CHECKPOINT),\n",
                "        config=config,\n",
                "    )\n",
                "    model.eval()\n",
                "    \n",
                "    # Create dummy input\n",
                "    dummy_input = torch.randn(\n",
                "        1, config.data.sequence_length, 3,\n",
                "        config.data.img_size, config.data.img_size\n",
                "    )\n",
                "    \n",
                "    # Export to TorchScript\n",
                "    print(\"üì¶ Exporting to TorchScript...\")\n",
                "    try:\n",
                "        scripted = torch.jit.trace(model.model, dummy_input)\n",
                "        torchscript_path = EXPORT_DIR / \"mamba_detector.pt\"\n",
                "        scripted.save(str(torchscript_path))\n",
                "        print(f\"‚úÖ Saved TorchScript model to: {torchscript_path}\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è TorchScript export failed: {e}\")\n",
                "        print(\"   This is expected with dynamic Mamba layers. Use checkpoint instead.\")\n",
                "    \n",
                "    # Also save as PyTorch checkpoint (more reliable)\n",
                "    torch_path = EXPORT_DIR / \"mamba_detector_final.ckpt\"\n",
                "    torch.save({\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'config': config,\n",
                "    }, torch_path)\n",
                "    print(f\"‚úÖ Saved PyTorch checkpoint to: {torch_path}\")\n",
                "else:\n",
                "    print(\"‚ùå No checkpoint found. Train the model first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéâ Training Complete!\n",
                "\n",
                "### Summary\n",
                "- Model trained on all UAV parts using incremental download-train-delete workflow\n",
                "- Final checkpoint saved to `outputs/checkpoints/latest.ckpt`\n",
                "- Exported model saved to `outputs/exported/`\n",
                "\n",
                "### Next Steps\n",
                "1. **Deploy to Lightning AI**: Upload the exported model for cloud inference\n",
                "2. **Hyperparameter Tuning**: Run `tune.py` for automated optimization\n",
                "3. **Multi-GPU Training**: Use `train.py` with DDP for faster training"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
